
import org.apache.spark.sql.{SQLContext, SparkSession}
object dfduplicate {
  def main(args: Array[String]): Unit = {
    val sparkSession = SparkSession.builder.
      master("local")
      .appName("spark session example")
      .getOrCreate()


    val df1 = sparkSession.read.option("header", "true").csv("C:\\Users\\xx\\Desktop\\TestFile1.csv")
    val df2 = sparkSession.read.option("header", "true").csv("C:\\Users\\xx\\Desktop\\TestFile2.csv")
    /*df1.show()
    df2.show()
    df1.createOrReplaceTempView("people1")
    df2.createOrReplaceTempView("people2")*/
// Ignore the above written 4 lines
    df1.union(df2).show()
    df1.intersect(df2).show()
  }
}
